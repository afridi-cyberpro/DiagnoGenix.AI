from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
import os
import pandas as pd
import numpy as np
import time
import warnings
warnings.filterwarnings(action="ignore")
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from keras.callbacks import LearningRateScheduler
annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)



Normal_dirs = [
    r'/content/drive/MyDrive/Diagno datset/normal'
]

Stone_dirs = [
    r'/content/drive/MyDrive/Diagno datset/stone'
]

filepaths = []
labels = []
dict_lists = [Normal_dirs, Stone_dirs]
class_labels = ['normal', 'stone']
print('Data prepared successfully ')

for i, dir_list in enumerate(dict_lists):
    for j in dir_list:
        flist = os.listdir(j)
        for f in flist:
            fpath = os.path.join(j, f)
            filepaths.append(fpath)
            labels.append(class_labels[i])

Fseries = pd.Series(filepaths, name="filepaths")
Lseries = pd.Series(labels, name="labels")
KIDNEY_data = pd.concat([Fseries, Lseries], axis=1)
KIDNEY_df = pd.DataFrame(KIDNEY_data)
KIDNEY_df


train_images, test_images = train_test_split(KIDNEY_df, test_size=0.3, random_state=42)
train_set, val_set = train_test_split(KIDNEY_df, test_size=0.2, random_state=42)
val_x = val_set["filepaths"]
val_y = val_set["labels"]


image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)
train = image_gen.flow_from_dataframe(dataframe= train_set,x_col="filepaths",y_col="labels",
                                      target_size=(244,244),
                                      color_mode='rgb',
                                      class_mode="categorical",
                                      batch_size=8,
                                      shuffle=False
                                     )
test = image_gen.flow_from_dataframe(dataframe= test_images,x_col="filepaths", y_col="labels",
                                     target_size=(244,244),
                                     color_mode='rgb',
                                     class_mode="categorical",
                                     batch_size=8,
                                     shuffle= False
                                    )
val = image_gen.flow_from_dataframe(dataframe= val_set,x_col="filepaths", y_col="labels",
                                    target_size=(244,244),
                                    color_mode= 'rgb',
                                    class_mode="categorical",
                                    batch_size=8,
                                    shuffle=False
                                   )

print(f"Number of images in train dataset: {train.n}")
print(f"Number of images in test dataset: {test.n}")
print(f"Number of images in validation dataset: {val.n}")
print(f"Class indices: {train.class_indices}")
print(f"Class indices: {test.class_indices}")
print(f"Class indices: {val.class_indices}")
print(f"Class distribution in train dataset: {train.classes}")
print(f"Class distribution in test dataset: {test.classes}")
print(f"Class distribution in validation dataset: {val.classes}")


def show_KIDNEY_images(image_gen):
    test_dict = test.class_indices
    classes = list(test_dict.keys())
    images, labels=next(image_gen) # get a sample batch from the generator
    plt.figure(figsize=(20,20))
    length = len(labels)
    r = min(length, 25)
    for i in range(r):
        plt.subplot(5,5,i+1)
        image=(images[i]+1)/2 #scale images between 0 and 1
        plt.imshow(image)
        index=np.argmax(labels[i])
        class_name=classes[index]
        plt.title(class_name, color="green",fontsize=16)
        plt.axis('off')
    plt.show()
show_KIDNEY_images(train)


def diagno_model():
  model = keras.models.Sequential([
    keras.layers.Conv2D(filters=128, kernel_size=(8, 8), strides=(3, 3), activation='relu', input_shape=(224, 224, 3)),
    keras.layers.BatchNormalization(),

    # keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding="same"),
    # keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3, 3)),

    keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),


    keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    #  keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding="same"),
    #  keras.layers.BatchNormalization(),

    #  keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding="same"),
    #  keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2, 2)),

    #  keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding="same"),
    #  keras.layers.BatchNormalization(),

    keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2, 2)),

    keras.layers.Flatten(),
    keras.layers.Dense(1024, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(1024, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(2, activation='softmax')
   ])
  return model

model = diagno_model()
model.summary()



model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipvalue=1.0),
    loss='binary_crossentropy',
    metrics=['accuracy']
)



# Start training time
start_time = time.time()

history = model.fit(train,
                    epochs=10,
                    validation_data=val,
                    verbose=1)

 # End training time
end_time = time.time()
training_time = end_time - start_time
print(f"Training Time: {training_time / 60:.2f} minutes")


test_loss, test_accuracy = model.evaluate(test, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


#Check the history data
print("History keys:", history.history.keys())
print("Training Accuracy:", history.history['accuracy'])
print("Validation Accuracy:", history.history['val_accuracy'])
print("Training Loss:", history.history['loss'])
print("Validation Loss:", history.history['val_loss'])

# Plot training and validation loss and accuracy
plt.figure(figsize=(14, 5))  # Adjusted size for better visibility

# Loss plot
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', color='red', linewidth=2, marker='o', linestyle='-')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange', linewidth=2, marker='o', linestyle='-')
plt.title('Loss Over Epochs', fontsize=14)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.legend(fontsize=10)
plt.grid(alpha=0.5)

# Accuracy plot
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2, marker='o', linestyle='-')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green', linewidth=2, marker='o', linestyle='-')
plt.title('Accuracy Over Epochs', fontsize=14)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.legend(fontsize=10)
plt.grid(alpha=0.5)

# Show plots
plt.tight_layout()  # Ensures no overlap between plots
plt.show()


pred = model.predict(test)
pred = np.argmax(pred, axis=1)

labels = (train.class_indices)
labels = dict((v,k) for k,v in labels.items())
pred2 = [labels[k] for k in pred]
pred2 = np.array(pred2)

y_test = test.classes

for i in range(5):
  print(f"Sample Prediction {i+1}:", pred2[i])
  print(f"True Label {i+1}:", labels[y_test[i]])
  print()




sample_images, _ = next(test)
sample_images = sample_images[:5]
sample_predictions = pred2[:5]
sample_true_labels = [labels[y_test[i]] for i in range(5)]

plt.figure(figsize=(15, 5))
for i in range(5):
  plt.subplot(1, 5, i + 1)
  plt.imshow((sample_images[i] + 1) / 2)
  plt.title(f"Pred: {sample_predictions[i]}\nTrue: {sample_true_labels[i]}")
  plt.axis('off')

plt.show()



y_test = test_images.labels
print("Classification Report:")
print(classification_report(y_test, pred2))
print('\n\n')
print("Accuracy of the Model:","{:.1f}%".format(accuracy_score(y_test, pred2)*100))


class_labels = ['Normal', 'Stone']


cm = confusion_matrix(y_test, pred2)

plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues')

plt.xticks(ticks=[0.5, 1.5], labels=class_labels)
plt.yticks(ticks=[0.5, 1.5], labels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")

plt.title("Confusion Matrix")

plt.show()


